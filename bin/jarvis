#!/usr/bin/env python3

from jarvis_cd.basic.jarvis_manager import JarvisManager
from jarvis_util import *
from jarvis_util.shell.slurm_exec import SlurmExec, SlurmExecInfo, SlurmHostfile
from jarvis_util.shell.pbs_exec import PbsExec, PbsExecInfo
from jarvis_cd.basic.pkg import Pipeline, PkgArgParse


class JarvisArgs(ArgParse):
    def define_options(self):
        self.jarvis = JarvisManager.get_instance()
        self.jutil = JutilManager.get_instance()
        self.define_init_opts()
        self.define_pipeline_opts()
        self.define_repo_opts()
        self.define_env_opts()
        self.jutil.debug_mpi_exec = False

    def define_init_opts(self):
        # jarvis init
        self.add_menu('init',
                      msg='Initialize jarvis cd configuration')
        self.add_args([
            {
                'name': 'CONFIG_DIR',
                'msg': 'A directory where jarvis metadata for pkgs and '
                       'pipelines are stored. This directory can be anywhere '
                       'that the current user can access.',
                'required': True,
                'pos': True
            },
            {
                'name': 'PRIVATE_DIR',
                'msg': 'A directory which is common across all machines, but '
                       'stores data locally to the machine',
                'required': True,
                'pos': True
            },
            {
                'name': 'SHARED_DIR',
                'msg': 'A directory which is common across all machines, '
                       'where each machine has the same view of data '
                       'in the directory',
                'default': None,
                'pos': True
            }
        ])

        # jarvis celan
        self.add_menu('reset',
                      msg='Clean all pipelines and configurations')

        # jarvis config print
        self.add_menu('config print',
                      msg='Print jarvis directories')

        # jarvis bootstrap
        self.add_menu('bootstrap',
                      msg='Bootstrap jarvis from a particular machine')

        # jarvis bootstrap from
        self.add_menu('bootstrap from',
                      msg='Initialize jarvis from an existing machine')
        self.add_args([
            {
                'name': 'MACHINE',
                'msg': 'The machine to bootstrap from',
                'required': True,
                'pos': True
            }
        ])

        # jarvis bootstrap list
        self.add_menu('bootstrap list',
                      msg='List all machines')

        # jarvis hostfile set
        self.add_menu('hostfile set',
                      msg='Define the hostfile for the job')
        self.add_args([
            {
                'name': 'path',
                'msg': 'The path to the hostfile of this job',
                'required': True,
                'pos': True,
                'default': None
            },
        ])

        # jarvis resource-graph
        self.add_menu('resource-graph',
                      msg='Resources to build a resource graph for a machine')

        # jarvis resource-graph init
        self.add_menu('resource-graph init',
                      msg='Create an empty resource graph')

        # jarvis resource-graph build
        self.add_menu('resource-graph build',
                      msg='Introspect resource graph for this machine')
        self.add_args([
            {
                'name': 'walkthrough',
                'msg': 'A guide for building a resource graph',
                'type': bool,
                'default': False
            },
            {
                'name': 'introspect',
                'msg': 'Whether or not to do an introspect before building',
                'type': bool,
                'default': True
            },
        ])

        # jarvis resource-graph build
        self.add_menu('resource-graph prune',
                      msg='An interactive CLI for modifying the resource graph')

        # jarvis resource-graph add storage
        self.add_menu('resource-graph add storage',
                      msg='Add a storage device or PFS to track')
        self.add_args([
            {
                'name': 'hostfile',
                'msg': 'The path to the hosts having the storage'
            },
            {
                'name': 'hosts',
                'msg': 'A hostfile string (e.g., ares-comp-[10-30])'
            },
            {
                'name': 'device',
                'msg': 'Device path (e.g., /dev/sda)'
            },
            {
                'name': 'mount',
                'msg': 'Where device is currently mounted'
            },
            {
                'name': 'tran',
                'msg': 'Whether the device is rotational',
                'choices': ['sata', 'nvme', 'dimm']
            },
            {
                'name': 'size',
                'msg': 'The size of the device (e.g., 16g, 32m ...)'
            },
            {
                'name': 'shared',
                'msg': 'Whether the mount is a pfs or not'
            },
        ])

        # jarvis resource-graph add net
        self.add_menu('resource-graph add net',
                      msg='Add a network to track')
        self.add_args([
            {
                'name': 'hostfile',
                'msg': 'The path to the hosts to add'
            },
            {
                'name': 'hosts',
                'msg': 'The networks to add as a hostfile string'
            },
            {
                'name': 'provider',
                'msg': 'Network protocol (e.g., tcp, sockets, ib)'
            },
            {
                'name': 'speed',
                'msg': 'Interconnect speed'
            },
        ])

        # jarvis resource-graph filter fs
        self.add_menu('resource-graph filter fs',
                      msg='Consider only mounts matching query')
        self.add_args([
            {
                'name': 'mount_re',
                'msg': 'A regex to match mountpoints',
                'required': True,
                'pos': True,
            },
            {
                'name': 'mount_suffix',
                'msg': 'Append a suffix to the mount point',
                'default': None
            },
        ])

        # jarvis resource-graph filter net
        self.add_menu('resource-graph filter net',
                      msg='Consider only mounts matching query')
        self.add_args([
            {
                'name': 'hostfile',
                'msg': 'Path to hostfile for networks to filter for',
            },
            {
                'name': 'hosts',
                'msg': 'Hostfile text for networks to filter for',
            },
            {
                'name': 'ip_re',
                'msg': 'A regex of IP addresess to filter for',
            },
            {
                'name': 'speed',
                'msg': 'Indicate speed of this network subset',
            },
        ])

    def define_repo_opts(self):
        # jarvis repo
        self.add_menu('repo',
                      msg='Tools to manage the Jarvis repos')

        # jarvis repo add
        self.add_menu('repo add',
                      msg='Register a jarvis repo')
        self.add_args([
            {
                'name': 'repo_path',
                'msg': 'The path to the repo in the filesystem',
                'required': True,
                'pos': True,
                'default': None
            },
        ])

        # jarvis repo create
        self.add_menu('repo create',
                      msg='Create a pkg in the primary repo')
        self.add_args([
            {
                'name': 'pkg_type',
                'msg': 'The name of the pkg to create',
                'required': True,
                'pos': True,
                'default': None
            },
            {
                'name': 'pkg_cls',
                'msg': 'The type of pkg to create',
                'required': True,
                'pos': True,
                'default': None,
                'choices': ['service', 'app', 'interceptor']
            },
        ])

        # jarvis repo promote
        self.add_menu('repo promote',
                      msg='Make a repo the primary repo for '
                          'subsequent repo create commands')
        self.add_args([
            {
                'name': 'repo_name',
                'msg': 'The name of the repo to promote',
                'required': True,
                'pos': True,
                'default': None
            },
        ])

        # jarvis repo remove
        self.add_menu('repo remove',
                      msg='Remove a repo from consideration')
        self.add_args([
            {
                'name': 'repo_name',
                'msg': 'The name of the repo to remove',
                'required': True,
                'pos': True,
                'default': None
            },
        ])

        # jarvis repo list
        self.add_menu('repo list',
                      msg='List the set of repos, or list the set of pkgs')
        self.add_args([
            {
                'name': 'repo_name',
                'msg': '',
                'required': False,
                'pos': True,
                'default': None
            },
        ])

    def define_pipeline_opts(self):
        # jarvis cd
        self.add_menu('cd',
                      msg='Make all jarvis operations apply to a '
                          'certain pipeline')
        self.add_args([
            {
                'name': 'pipeline_id',
                'msg': 'The unique name of the pipeline to switch to',
                'required': True,
                'pos': True,
                'default': None
            },
        ])
        self.add_menu('getcwd',
                      msg='Get currently focused pipeline')

        # jarvis path
        self.add_menu('path',
                      msg='Get the path of a jarvis pipeline or pkg')
        self.add_args([
            {
                'name': 'pipeline_id',
                'msg': 'The name of the pipeline to get config path for',
                'required': False,
                'pos': True,
                'default': None
            },
            {
                'name': 'pkg_id',
                'msg': 'The name of the pkg to get the path for',
                'default': None,
                'pos': True,
                'required': False,
                'default': None
            },
            {
                'name': 'config',
                'msg': 'Get the config directory path',
                'required': False,
                'type': bool,
                'pos': False,
                'default': True
            },
            {
                'name': 'shared',
                'msg': 'Get the shared directory path',
                'required': False,
                'type': bool,
                'pos': False,
                'default': False
            },
            {
                'name': 'private',
                'msg': 'Get the private directory path',
                'required': False,
                'type': bool,
                'pos': False,
                'default': False
            },
        ])

        # jarvis pipeline
        self.add_menu('pipeline',
                      msg='Tools to create + edit a pipeline')

        # jarvis pipeline list
        self.add_menu('pipeline list',
                      msg='List all created pipelines')
        self.add_args([
            {
                'name': 'pipeline_id',
                'msg': 'The pipeline to list. Default None to list the'
                       'set of pipelines',
                'required': False,
                'pos': True,
                'default': None
            },
        ])

        # jarvis pipeline create
        self.add_menu('pipeline create',
                      msg='Create a pipeline')
        self.add_args([
            {
                'name': 'pipeline_id',
                'msg': 'A unique name for this pipeline',
                'required': True,
                'pos': True,
                'default': None
            },
        ])

        # jarvis pipeline load yaml
        self.add_menu('pipeline load yaml',
                      msg='Create a pipeline from a yaml schema')
        self.add_args([
            {
                'name': 'path',
                'msg': 'The pipeline schema file path',
                'required': True,
                'pos': True,
                'default': None
            },
            {
                'name': 'conf',
                'msg': 'Whether to configure the pipeline immediately',
                'required': False,
                'pos': False,
                'default': True
            },
        ])

        # jarvis pipeline run yaml
        self.add_menu('pipeline run yaml',
                      msg='Create a pipeline from a yaml schema')
        self.add_args([
            {
                'name': 'path',
                'msg': 'The pipeline schema file path',
                'required': True,
                'pos': True,
                'default': None
            },
        ])

        # jarvis pipeline iterate
        self.add_menu('pipeline iterate',
                      msg='Create a pipeline from a yaml schema and iterate')
        self.add_args([
            {
                'name': 'path',
                'msg': 'The pipeline schema file path',
                'required': True,
                'pos': True,
                'default': None
            },
        ])

        # jarvis pipeline print
        self.add_menu('pipeline print', msg="List all pkgs in a pipeline.")
        self.add_args([
            {
                'name': 'pipeline_id',
                'msg': 'The pipeline to list. Default None to list the'
                       'set of pipelines',
                'required': False,
                'pos': True,
                'default': None
            },
        ])

        # jarvis pipeline reset
        self.add_menu('pipeline reset', msg='Clear a pipeline')
        self.add_args([
            {
                'name': 'pipeline_id',
                'msg': 'Delete the jarvis directories containing metadata'
                       'for the pipeline. Will apply to current pipeline by'
                       'default.',
                'required': False,
                'pos': True,
                'default': None
            },
        ])

        # jarvis pipeline destroy
        self.add_menu('pipeline destroy', msg='Delete a pipeline')
        self.add_args([
            {
                'name': 'pipeline_id',
                'msg': 'Delete the jarvis directories containing metadata'
                       'for the pipeline. Will apply to current pipeline by'
                       'default.',
                'required': False,
                'pos': True,
                'default': None
            },
        ])

        # jarvis pipeline update
        self.add_menu('pipeline update', msg='Re-run configure on all pkgs '
                                             'in a pipeline')

        # jarvis pipeline append
        self.add_menu('pipeline append',
                      msg='Append a pkg to a pipeline',
                      keep_remainder=True)
        self.add_args([
            {
                'name': 'pkg_type',
                'msg': 'The type of pkg being added to the pipeline',
                'required': True,
                'pos': True,
                'default': None
            },
            {
                'name': 'pkg_id',
                'msg': 'The unique name of the pkg being added to '
                       'the pipeline. By default, will be equal to '
                       'pkg_type',
                'required': False,
                'pos': True,
                'default': None
            },
            {
                'name': 'conf',
                'msg': 'Should be run the configure step on the pkg',
                'required': False,
                'pos': False,
                'default': True,
                'type': bool
            },
        ])

        # jarvis pipeline prepend
        self.add_menu('pipeline prepend',
                      msg='Prepend a pkg to a pipeline',
                      keep_remainder=True)
        self.add_args([
            {
                'name': 'pkg_type',
                'msg': 'The type of pkg being added to the pipeline',
                'required': True,
                'pos': True,
                'default': None
            },
            {
                'name': 'pkg_id',
                'msg': 'The unique name of the pkg being added to '
                       'the pipeline. By default, will be equal to '
                       'pkg_type',
                'required': False,
                'pos': True,
                'default': None
            },
            {
                'name': 'conf',
                'msg': 'Should be run the configure step on the pkg',
                'required': False,
                'pos': False,
                'default': True,
                'type': bool
            },
        ])

        # jarvis pipeline insert
        self.add_menu('pipeline insert',
                      msg='Prepend a pkg to a pipeline',
                      keep_remainder=True)
        self.add_args([
            {
                'name': 'at_id',
                'msg': 'The id of the packge to insert at',
                'required': True,
                'pos': True,
                'default': None
            },
            {
                'name': 'pkg_type',
                'msg': 'The type of pkg being added to the pipeline',
                'required': True,
                'pos': True,
                'default': None
            },
            {
                'name': 'pkg_id',
                'msg': 'The unique name of the pkg being added to '
                       'the pipeline. By default, will be equal to '
                       'pkg_type',
                'required': False,
                'pos': True,
                'default': None
            },
            {
                'name': 'conf',
                'msg': 'Should be run the configure step on the pkg',
                'required': False,
                'pos': False,
                'default': True,
                'type': bool
            },
        ])

        # pipeline env build
        self.add_menu('pipeline env build',
                      msg="Cache relevant environment vars. Use +ENV_VAR and"
                          "-ENV_VAR in remainder list to indicate whether "
                          "to track certain variables.",
                      keep_remainder=True,
                      remainder_as_kv=True)

        # jarvis pipeline env scan
        self.add_menu('pipeline env scan',
                      msg="Reload environment vars. Use +ENV_VAR to indicate"
                          "which variables to track.",
                      keep_remainder=True,
                      remainder_as_kv=True)

        # jarvis pipeline env track
        self.add_menu('pipeline env track',
                      msg="Add or remove environment vars. Use +ENV_VAR and"
                          "-ENV_VAR in remainder list to indicate whether "
                          "to track certain variables.",
                      keep_remainder=True)

        # jarvis pipeline
        self.add_menu('pkg',
                      msg='Tools to edit pkgs in a pipeline')

        # jarvis pkg configure
        self.add_menu('pkg configure',
                      msg="Configure a pkg in the pipeline",
                      keep_remainder=True)
        self.add_args([
            {
                'name': 'pkg_id',
                'msg': 'The unique name of the pkg being added to '
                       'the pipeline.',
                'required': True,
                'pos': True,
                'default': None
            },
            {
                'name': 'conf',
                'msg': 'Should be run the configure step on the pkg',
                'required': False,
                'pos': False,
                'default': True,
                'type': bool
            },
        ])

        # jarvis pkg unlink
        self.add_menu('pkg unlink', msg="Unlink a pkg from the pipeline.")
        self.add_args([
            {
                'name': 'pkg_id',
                'msg': 'The unique name of the pkg being added to '
                       'the pipeline.',
                'required': True,
                'pos': True,
                'default': None
            },
        ])

        # jarvis pkg remove
        self.add_menu('pkg remove', msg="Remove a pkg from the pipeline.")
        self.add_args([
            {
                'name': 'pkg_id',
                'msg': 'The unique name of the pkg removed',
                'required': True,
                'pos': True,
                'default': None
            },
        ])

        # jarvis pipeline [run/start/stop/clean/status]
        self.add_menu('pipeline run',
                      msg="Run + terminate a pipeline",
                      keep_remainder=True)
        self.add_args([
            {
                'name': 'pipeline_name',
                'msg': 'The pipeline name to be run',
                'required': False,
                'pos': True,
                'default': None
            },
            {
                'name': 'slurm_host',
                'msg': 'This is a SLURM job',
                'required': False,
                'pos': False,
                'default': False,
                'type': bool
            },
            {
                'name': 'pbs_host',
                'msg': 'This is a PBS job',
                'required': False,
                'pos': False,
                'default': False,
                'type': bool
            },
            {
                'name': 'polaris',
                'msg': 'This is a PBS job on Polaris',
                'required': False,
                'pos': False,
                'default': False,
                'type': bool
            },
            {
                'name': 'host_suffix',
                'msg': 'A suffix to append to hostfile',
                'required': False,
                'pos': False,
                'default': None,
                'type': str
            },
        ])

        self.add_menu('pipeline start',
                      msg="Start a pipeline",
                      keep_remainder=True)
        self.add_menu('pipeline stop',
                      msg="Stop a pipeline",
                      keep_remainder=True)
        self.add_menu('pipeline kill',
                      msg="Kill a pipeline",
                      keep_remainder=True)
        self.add_menu('pipeline clean',
                      msg="Clean a pipeline",
                      keep_remainder=True)
        self.add_menu('pipeline status',
                      msg="Get the status of a pipeline",
                      keep_remainder=True)
        self.add_menu('pipeline load',
                      msg="Load a pipeline from a file",
                      keep_remainder=True)
        self.add_args([
            {
                'name': 'path',
                'msg': 'Path to the file or folder to load the pipeline',
                'required': True,
                'pos': True,
                'default': None
            }
        ])
        self.add_menu('pipeline save',
                      msg="Save the current pipeline",
                      keep_remainder=True)

        # jarvis pipeline sbatch
        self.add_menu('pipeline sbatch', msg="Run the current pipeline through sbatch")
        self.add_args([
            {
                'name': 'job_name',
                'msg': 'The name given to this job',
                'required': True,
                'pos': False,
                'default': None
            },
            {
                'name': 'nnodes',
                'msg': 'The number of nodes to execute the pipeline on',
                'required': True,
                'pos': False,
                'default': None
            },
            {
                'name': 'ppn',
                'msg': 'The number of processes per node',
                'required': False,
                'pos': False,
                'default': None
            },
            {
                'name': 'cpus_per_task',
                'msg': 'Advise the Slurm controller that ensuing job will require ncpus number of processors per task',
                'required': False,
                'pos': False,
                'default': None
            },
            {
                'name': 'time',
                'msg': 'Maximum time aloted to the job',
                'required': False,
                'pos': False,
                'default': None
            },
            {
                'name': 'partition',
                'msg': 'The partition in which to allocate the nodes',
                'required': False,
                'pos': False,
                'default': 'compute'
            },
            {
                'name': 'mail_type',
                'msg': 'When to email users of the status of the job',
                'required': False,
                'pos': False,
                'default': None,
                'choices': ['NONE', 'BEGIN', 'END', 'FAIL', 'REQUEUE', 'ALL']
            },
            {
                'name': 'mail_user',
                'msg': 'What email to use',
                'required': False,
                'pos': False,
                'default': None,
            },
            {
                'name': 'output_file',
                'msg': 'File to write all output messages',
                'required': False,
                'pos': False,
                'default': None
            },
            {
                'name': 'error_file',
                'msg': 'File to write all error messages',
                'required': False,
                'pos': False,
                'default': None
            },
            {
                'name': 'memory',
                'msg': 'Amount of memory to request for the job',
                'required': False,
                'pos': False,
                'default': None
            },
            {
                'name': 'gres',
                'msg': 'A comma-delimited list of generic consumable resources, like gpus',
                'required': False,
                'pos': False,
                'default': None
            },
            {
                'name': 'exclusive',
                'msg': 'Request the nodes exclusively',
                'required': False,
                'pos': False,
                'default': True
            },
            {
                'name': 'host_suffix',
                'msg': 'Append suffix to all hosts in hostfile',
                'required': False,
                'pos': False,
                'type': str,
                'default': None
            },
        ])

        self.add_menu('pipeline pbs', msg="Run the current pipeline through pbs")
        self.add_args([
            {
                'name': 'nnodes',
                'msg': 'The number of nodes to execute the pipeline on',
                'required': True,
                'pos': False,
                'default': 1
            },
            {
                'name': 'system',
                'msg': 'The type of system to allocate the nodes on',
                'required': False,
                'pos': False,
                'default': 'polaris'
            },
            {
                'name': 'filesystems',
                'msg': 'The filesystem to be used (e.g. home:grand)',
                'required': False,
                'pos': False,
                'default': 'home:grand'
            },
            {
                'name': 'walltime',
                'msg': 'Maximum time allotted to the job',
                'required': False,
                'pos': False,
                'default': '00:10:00'
            },
            {
                'name': 'account',
                'msg': 'Account used for job submission',
                'required': False,
                'pos': False,
                'default': 'VeloC'
            },
            {
                'name': 'queue',
                'msg': 'Queue in which to submit the job',
                'required': False,
                'pos': False,
                'default': 'debug-scaling'
            },
            {
                'name': 'interactive',
                'msg': 'Submit the job in interactive mode',
                'required': False,
                'pos': False,
                'default': False,
                'type': bool
            },
            {
                'name': 'env_vars',
                'msg': 'Environmental variables to pass through PBS. '
                       'Comma separated list of strings of the form variable or variable=value',
                'required': False,
                'pos': False,
                'default': None
            },
            {
                'name': 'polaris',
                'msg': 'Submit using polaris',
                'required': False,
                'pos': False,
                'default': False,
                'type': bool
            },
        ])

        self.add_menu('generate bash complete',
                      msg='Generate bash completion script for jarvis')

    def define_env_opts(self):
        # jarvis env build
        self.add_menu('env build',
                      msg="Create a custom environment.",
                      keep_remainder=True,
                      remainder_as_kv=True)
        self.add_args([
            {
                'name': 'env_name',
                'msg': 'The name of the environment to create',
                'required': True,
                'pos': True,
                'default': None
            },
        ])

        # jarvis env destroy
        self.add_menu('env destroy',
                      msg="Destroy a custom environment.")
        self.add_args([
            {
                'name': 'env_name',
                'msg': 'The name of the environment to destroy',
                'required': True,
                'pos': True,
                'default': None
            },
        ])

        # jarvis env list
        self.add_menu('env list',
                      msg="List all custom environments.")

        # jarvis pipeline env copy
        self.add_menu('pipeline env copy',
                      msg="Copy and modify a custom environment.",
                      keep_remainder=True,
                      remainder_as_kv=True)
        self.add_args([
            {
                'name': 'env_name',
                'msg': 'The name of the environment to create',
                'required': True,
                'pos': True,
                'default': None
            },
        ])

    """
    INITIALIZATION CLI
    """

    def init(self):
        self.jarvis.create(self.kwargs['CONFIG_DIR'],
                           self.kwargs['PRIVATE_DIR'],
                           self.kwargs['SHARED_DIR'])

    def config_print(self):
        self.jarvis.print_config()

    def bootstrap_from(self):
        self.jarvis.bootstrap_from(self.kwargs['MACHINE'])

    def bootstrap_list(self):
        self.jarvis.bootstrap_list()

    def reset(self):
        while True:
            x = input('Are you sure you want to destroy all pipelines? '
                      '(yes/no): ')
            if x == 'yes':
                break
            elif x == 'no':
                print('Not removing anything.')
                return
            else:
                print(f'{x} is neither yes or no')
        self.jarvis.reset()

    """
    RESOURCE GRAPH CLI
    """

    def hostfile_set(self):
        self.jarvis.set_hostfile(self.kwargs['path'])
        pipelines = self.jarvis.list_pipelines()
        for pipeline in pipelines:
            Pipeline().load(pipeline).update().save()
        self.jarvis.save()

    def resource_graph_init(self):
        self.jarvis.resource_graph_init()
        self.jarvis.save()

    def resource_graph_build(self):
        walkthrough = self.kwargs['walkthrough']
        introspect = self.kwargs['introspect']
        if walkthrough:
            self.jarvis.resource_graph.walkthrough_build(
                PsshExecInfo(hostfile=self.jarvis.hostfile),
                introspect)
        else:
            self.jarvis.resource_graph_build()
        self.jarvis.save()

    def resource_graph_prune(self):
        self.jarvis.resource_graph.walkthrough_prune(
            PsshExecInfo(hostfile=self.jarvis.hostfile))

    def resource_graph_add_storage(self):
        self._resource_graph_hostfile()
        self.jarvis.resource_graph.add_storage(**self.kwargs)
        self.jarvis.save()

    def resource_graph_add_net(self):
        self._resource_graph_hostfile()
        self.jarvis.resource_graph.add_net(**self.kwargs)
        self.jarvis.save()

    def resource_graph_filter_fs(self):
        self.jarvis.resource_graph.filter_fs(**self.kwargs)
        self.jarvis.save()

    def resource_graph_filter_net(self):
        self._resource_graph_hostfile()
        self.jarvis.resource_graph.filter_net(**self.kwargs)
        self.jarvis.save()

    def _resource_graph_hostfile(self):
        if self.kwargs['hosts'] is not None:
            self.kwargs['hosts'] = Hostfile(text=self.kwargs['hosts'])
        elif self.kwargs['hostfile'] is not None:
            self.kwargs['hosts'] = Hostfile(hostfile=self.kwargs['hostfile'])
        else:
            self.kwargs['hosts'] = self.jarvis.hostfile
        del self.kwargs['hostfile']

    """
    REPO CLI
    """

    def repo_add(self):
        self.jarvis.add_repo(self.kwargs['repo_path'])
        self.jarvis.save()

    def repo_create(self):
        pkg_cls = self.kwargs['pkg_cls']
        pkg_type = self.kwargs['pkg_type']
        self.jarvis.create_pkg(pkg_cls, pkg_type)
        self.jarvis.save()

    def repo_promote(self):
        self.jarvis.promote_repo(self.kwargs['repo_name'])
        self.jarvis.save()

    def repo_remove(self):
        self.jarvis.remove_repo(self.kwargs['repo_name'])
        self.jarvis.save()

    def repo_list(self):
        if self.kwargs['repo_name'] is not None:
            self.jarvis.list_repo(self.kwargs['repo_name'])
        else:
            self.jarvis.list_repos()

    """
    ENV CLI
    """

    def env_build(self):
        kwargs = {}
        kwargs.update(self.kwargs)
        kwargs.update(self.remainder_kv)
        Pipeline().build_static_env(kwargs['env_name'], kwargs)

    def env_destroy(self):
        Pipeline().destroy_static_env(self.kwargs['env_name'])

    def env_list(self):
        Pipeline().list_static_env()

    """
    PIPELINE CLI
    """

    def cd(self):
        self.jarvis.cd(self.kwargs['pipeline_id'])
        self.jarvis.save()

    def path(self):
        pipeline_id = self.kwargs['pipeline_id']
        pkg_id = self.kwargs['pkg_id']
        config = self.kwargs['config']
        shared = self.kwargs['shared']
        private = self.kwargs['private']
        pipeline = Pipeline().load(pipeline_id, with_config=False)
        if pkg_id is not None:
            path = pipeline.get_pkg(pkg_id).get_path(config, shared, private)
        else:
            path = pipeline.get_path(config, shared, private)
        print(path)

    def getcwd(self):
        print(self.jarvis.cur_pipeline)

    def pipeline_list(self):
        for pipeline_ctx in self.jarvis.list_pipelines():
            print(pipeline_ctx)

    def pipeline_create(self):
        pipeline_id = self.kwargs['pipeline_id']
        Pipeline().create(pipeline_id).save()
        self.jarvis.cd(pipeline_id)
        self.jarvis.save()

    def pipeline_load_yaml(self):
        path = self.kwargs['path']
        pipeline = Pipeline().from_yaml(path).save()
        self.jarvis.cd(pipeline.global_id)
        self.jarvis.save()

    def pipeline_run_yaml(self):
        path = self.kwargs['path']
        pipeline = Pipeline().from_yaml(path).save()
        self.jarvis.cd(pipeline.global_id)
        pipeline.run()
        self.jarvis.save()
        exit(pipeline.exit_code)

    def pipeline_iterate(self):
        # path = self.kwargs['path']
        # params = YamlFile(path).load()
        # case_list = []
        # for key, val_list in params.items():
        #     if isinstance(val_list, list):
        #         case_list.append([(key, val) for val in val_list])
        # cases = itertools.product(*case_list)
        # for case in cases:
        #     key = case[0]
        #     val = case[1]
        #     params[key] = val
        #     pipeline = Pipeline().from_dict(path).save()
        # self.jarvis.cd(pipeline.global_id)
        # self.jarvis.save()
        pass

    def pipeline_reset(self):
        pipeline_id = self.kwargs['pipeline_id']
        Pipeline().load(pipeline_id, with_config=False).reset()
        self.jarvis.save()

    def pipeline_destroy(self):
        pipeline_id = self.kwargs['pipeline_id']
        Pipeline().load(pipeline_id).destroy()
        self.jarvis.save()

    def pipeline_print(self):
        pipeline_id = self.kwargs['pipeline_id']
        Pipeline().load(pipeline_id).view_pkgs()

    def pipeline_env_build(self):
        kwargs = {}
        kwargs.update(self.kwargs)
        kwargs.update(self.remainder_kv)
        Pipeline().load().build_env(kwargs).save()

    def pipeline_env_copy(self):
        kwargs = {}
        kwargs.update(self.kwargs)
        kwargs.update(self.remainder_kv)
        Pipeline().load().copy_static_env(kwargs['env_name'], kwargs).save()

    def pipeline_env_track(self):
        kwargs = {}
        kwargs.update(self.kwargs)
        kwargs.update(self.remainder_kv)
        Pipeline().load().track_env(kwargs.keys()).save()

    def pipeline_env_scan(self):
        Pipeline().load().scan_env(self.kwargs).save()

    def maybe_configure(self, pipeline, pkg_id):
        pkg = pipeline.get_pkg(pkg_id)
        menu = pkg.configure_menu()
        args = PkgArgParse(args=self.remainder, menu=menu)
        if self.kwargs['conf']:
            pipeline.configure(pkg_id, **args.kwargs)
        else:
            pkg.update_env(pipeline.env)
            pkg.update_config(args.kwargs)
        pipeline.save()

    def pipeline_append(self):
        pkg_id = self.kwargs['pkg_id']
        pipeline = Pipeline().load()
        if pkg_id is None:
            pkg_id = self.kwargs['pkg_type']
        pipeline.append(self.kwargs['pkg_type'],
                        pkg_id=pkg_id,
                        do_configure=False)
        self.maybe_configure(pipeline, pkg_id)

    def pipeline_prepend(self):
        pkg_id = self.kwargs['pkg_id']
        pipeline = Pipeline().load()
        if pkg_id is None:
            pkg_id = self.kwargs['pkg_type']
        pipeline.prepend(self.kwargs['pkg_type'],
                         pkg_id=pkg_id,
                         do_configure=False)
        self.maybe_configure(pipeline, pkg_id)

    def pipeline_insert(self):
        at_id = self.kwargs['at_id']
        pkg_id = self.kwargs['pkg_id']
        pipeline = Pipeline().load()
        if pkg_id is None:
            pkg_id = self.kwargs['pkg_type']
        pipeline.insert(self.kwargs['at_id'],
                        self.kwargs['pkg_type'],
                        pkg_id=pkg_id,
                        do_configure=False)
        self.maybe_configure(pipeline, pkg_id)

    def pipeline_update(self):
        Pipeline().load().update().save()

    def pkg_unlink(self):
        Pipeline().load().unlink(self.kwargs['pkg_id']).save()

    def pkg_remove(self):
        Pipeline().load().remove(self.kwargs['pkg_id']).save()

    def pkg_configure(self):
        pipeline = Pipeline().load()
        pkg = pipeline.get_pkg(self.kwargs['pkg_id'])
        menu = pkg.configure_menu()
        args = PkgArgParse(args=self.remainder, menu=menu)
        if self.kwargs['conf']:
            if args.kwargs['reinit']:
                pkg.configure(**args.kwargs)
            else:
                pkg.configure(**args.real_kwargs)
        else:
            pkg.update_env(pipeline.env)
            pkg.update_config(args.kwargs)
        pipeline.save()

    def pipeline_run(self):
        pipeline_name = self.kwargs['pipeline_name']
        pipeline = Pipeline().load(pipeline_name)
        file_location = os.path.join(pipeline.config_dir,
                                     'hostfile.txt')
        if self.kwargs['slurm_host']:
            SlurmHostfile(file_location, self.kwargs['host_suffix'])
            self.jarvis.set_hostfile(file_location)
            pipeline.update().save()  # this calls the config step
        if self.kwargs['pbs_host']:
            orig_nodefile = os.environ.get('PBS_NODEFILE')
            if self.kwargs['polaris']:
                hostfile = Hostfile(hostfile=orig_nodefile)
                for i, host in enumerate(hostfile.hosts):
                    hostfile.hosts[i] = host.split('.')[0]
            hostfile.save(file_location)
            self.jarvis.set_hostfile(file_location)
            pipeline.update().save()  # this calls the config step
        pipeline.run()
        exit(pipeline.exit_code)

    def pipeline_sbatch(self):
        pipeline_name = Pipeline().load().global_id
        if not self.kwargs['job_name']:
            job_name = f'{pipeline_name}_{self.kwargs["nnodes"]}'
            print(f'No name set for the job. Setting it to {job_name}')
            self.kwargs['job_name'] = job_name
        slurm_info = SlurmExecInfo(
            job_name=self.kwargs['job_name'],
            num_nodes=self.kwargs['nnodes'],
            ppn=self.kwargs['ppn'],
            cpus_per_task=self.kwargs['cpus_per_task'],
            time=self.kwargs['time'],
            partition=self.kwargs['partition'],
            mail_type=self.kwargs['mail_type'],
            mail_user=self.kwargs['mail_user'],
            pipe_stdout=self.kwargs['output_file'],
            pipe_stderr=self.kwargs['error_file'],
            mem=self.kwargs['memory'],
            gres=self.kwargs['gres'],
            exclusive=self.kwargs['exclusive'],
            host_suffix=self.kwargs['host_suffix']
        )
        slurm_cmd = [
            f'jarvis pipeline run {pipeline_name} +slurm_host'
        ]
        if slurm_info.host_suffix is not None:
            slurm_cmd.append(f'host_suffix={slurm_info.host_suffix}')
        slurm_cmd = ' '.join(slurm_cmd)
        SlurmExec(slurm_cmd, slurm_info)

    def pipeline_pbs(self):
        pipeline = Pipeline().load()
        pipeline_name = pipeline.global_id
        num_nodes = self.kwargs['nnodes']
        script_location = f'{pipeline.config_dir}/{pipeline_name}_{num_nodes}.sh'
        pbs_info = PbsExecInfo(
            nnodes=self.kwargs['nnodes'],
            system=self.kwargs['system'],
            filesystems=self.kwargs['filesystems'],
            walltime=self.kwargs['walltime'],
            account=self.kwargs['account'],
            queue=self.kwargs['queue'],
            interactive=self.kwargs['interactive'],
            bash_script=script_location
        )
        cmd = [
            f'jarvis pipeline run {pipeline_name} +pbs_host'
        ]
        if self.kwargs['polaris']:
            cmd.append('+polaris')
        cmd = ' '.join(cmd)
        PbsExec(cmd, pbs_info)

    def pipeline_start(self):
        Pipeline().load().start()

    def pipeline_stop(self):
        Pipeline().load().stop()

    def pipeline_kill(self):
        Pipeline().load().kill()

    def pipeline_clean(self):
        Pipeline().load().clean()

    def pipeline_status(self):
        Pipeline().load().status()

    def pipeline_load(self):
        Pipeline().load().status()

    def pipeline_save(self):
        Pipeline().load().status()

    def generate_bash_completion_script(self):
        bash_script = "#!/bin/bash\n"
        bash_script += "_jarvis_completion() {\n"
        bash_script += "    local cur prev opts\n"
        bash_script += "    COMPREPLY=()\n"
        bash_script += "    cur=\"${COMP_WORDS[COMP_CWORD]}\"\n"
        bash_script += "    prev=\"${COMP_WORDS[COMP_CWORD-1]}\"\n"

        # Handling each menu item
        for menu in self.menus:
            # Check if 'args' key exists
            if 'args' in menu:
                # Check for special cases like 'pipeline append'
                if menu['name'] == 'pipeline append':
                    # Special handling for 'pipeline append'
                    bash_script += "    if [[ $prev == 'pipeline' ]]; then\n"
                    bash_script += "        if [[ $cur == 'append'* ]]; then\n"
                    bash_script += "            local pkg_ids=$(jarvis repo list)  # Fetching pkg_ids dynamically\n"
                    bash_script += "            COMPREPLY=( $(compgen -W \"$pkg_ids\" -- $cur) )\n"
                    bash_script += "            return 0\n"
                    bash_script += "        fi\n"
                    bash_script += "    fi\n"
                else:
                    # Default handling for other commands
                    opts = " ".join([arg['name'] + "=" for arg in menu['args']])
                    bash_script += "    if [[ $prev == '{}']]; then\n".format(menu['name'])
                    bash_script += "        opts=\"" + opts + "\"\n"
                    bash_script += "    fi\n"

        bash_script += "    COMPREPLY=( $(compgen -W \"$opts\" -- $cur) )\n"
        bash_script += "    return 0\n"
        bash_script += "}\n"
        bash_script += "complete -F _jarvis_completion jarvis\n"

        # Write to file
        with open('jarvis_autocomplete.sh', 'w') as file:
            file.write(bash_script)
        print("Bash completion script generated: jarvis_autocomplete.sh")



if __name__ == '__main__':
    args = JarvisArgs()
    args.process_args()

